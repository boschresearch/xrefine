diff --git a/pixsfm/features/extractor.py b/pixsfm/features/extractor.py
index 3dd3717..16c1e56 100644
--- a/pixsfm/features/extractor.py
+++ b/pixsfm/features/extractor.py
@@ -1,4 +1,3 @@
-
 import inspect
 from omegaconf import DictConfig, OmegaConf
 import PIL
@@ -8,6 +7,7 @@ from pathlib import Path
 from typing import Tuple
 import pprint
 from typing import Optional
+import cv2
 
 from . import models
 from .models.base_model import BaseModel
@@ -16,10 +16,24 @@ from .._pixsfm import _features as features
 from ..util.misc import check_memory
 from .. import logger
 
+try:
+    from submodules.glue_factory.gluefactory.utils.image import ImagePreprocessor
+    from submodules.glue_factory.gluefactory.utils.image import load_image
+except ImportError:
+    print("Gluefactory not available. ")
+    pass
+
+import torchvision.transforms.functional as TF
+
+
+def tensor_to_pil(image_tensor: torch.Tensor) -> PIL.Image.Image:
+    # Make sure the tensor is [C, H, W] and in [0,1]
+    return TF.to_pil_image(image_tensor)
+
 
 def dynamic_load(root, model):
-    module_path = f'{root.__name__}.{model}'
-    module = __import__(module_path, fromlist=[''])
+    module_path = f"{root.__name__}.{model}"
+    module = __import__(module_path, fromlist=[""])
     classes = inspect.getmembers(module, inspect.isclass)
     # Filter classes defined in the module
     classes = [c for c in classes if c[1].__module__ == module_path]
@@ -29,49 +43,58 @@ def dynamic_load(root, model):
     return classes[0][1]
 
 
+def load_and_resize_img_kitti(img_file, resize_image_to_width, resize_image_to_height):
+    """
+    Partially copied from: https://github.com/eric-yyjau/pytorch-deepFEPE
+    Load an image and resize it to the specified size.
+    """
+    img = cv2.imread(img_file)
+    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
+    zoom_x = 1.0
+    zoom_y = 1.0
+    if resize_image_to_width > 0 and resize_image_to_height > 0:
+        if [resize_image_to_height, resize_image_to_width] != [img.shape[0], img.shape[1]]:  # H, W
+            zoom_y = resize_image_to_height / img.shape[0]
+            zoom_x = resize_image_to_width / img.shape[1]
+            img = cv2.resize(img, dsize=[resize_image_to_width, resize_image_to_height])
+    return img
+
+
 class FeatureExtractor:
     default_conf = {
-        'device': 'auto',
-        'dtype': 'half',
-        'fast_image_load': False,
-        'l2_normalize': True,
-        'max_edge': 1600,
-        'model': {
+        "device": "auto",
+        "dtype": "half",
+        "fast_image_load": False,
+        "l2_normalize": True,
+        "max_edge": 1600,
+        "model": {
             "name": "s2dnet",
             # model params
         },
-        'patch_size': 16,
-        'pyr_scales': [1.0],
-        'resize': 'LANCZOS',
-        'sparse': True,
-        'use_cache': False,
-        'overwrite_cache': False,
-        'load_cache_on_init': False,  # Disables reloading features on demand
-        'cache_format': 'chunked',
+        "patch_size": 16,
+        "pyr_scales": [1.0],
+        "resize": "LANCZOS",
+        "sparse": True,
+        "use_cache": False,
+        "overwrite_cache": False,
+        "load_cache_on_init": False,  # Disables reloading features on demand
+        "cache_format": "chunked",
     }
     device = None
 
-    dtype_map = {
-        dtype: getattr(torch, dtype) for dtype in ["float", "half", "double"]
-    }
+    dtype_map = {dtype: getattr(torch, dtype) for dtype in ["float", "half", "double"]}
 
-    dtype_to_bytes = {
-        "half": 2,
-        "float": 4,
-        "double": 8
-    }
+    dtype_to_bytes = {"half": 2, "float": 4, "double": 8}
 
-    filters = {
-        n: getattr(PIL.Image, n)
-        for n in ["BILINEAR", "BICUBIC", "LANCZOS"]
-    }
+    filters = {n: getattr(PIL.Image, n) for n in ["BILINEAR", "BICUBIC", "LANCZOS"]}
 
-    def __init__(self, conf: DictConfig, model: BaseModel = None):
+    def __init__(self, conf: DictConfig, model: BaseModel = None, dataset: Optional[str] = None):
         self.conf = conf = OmegaConf.merge(self.default_conf, conf)
 
         self.device = conf.device
         if self.device == "auto":
             self.device = "cuda" if torch.cuda.is_available() else "cpu"
+            print("PixSfM using device: ", self.device)
 
         if model is None:
             model = dynamic_load(models, conf.model.name)(conf.model)
@@ -84,15 +107,25 @@ class FeatureExtractor:
         for _ in self.conf.pyr_scales:
             self.channels_per_level += self.model.output_dims
 
-        logger.info('Loaded dense extractor with configuration:\n'
-                    f'{pprint.pformat(dict(self.conf))}')
+        logger.info("Loaded dense extractor with configuration:\n" f"{pprint.pformat(dict(self.conf))}")
+
+        self.dataset = dataset
+        if self.dataset in ["megadepth", "scannet1500"]:
+            if self.dataset == "megadepth":
+                conf = {"resize": 1024, "side": "long"}
+            elif self.dataset == "scannet1500":
+                conf = {"resize": (480, 640)}
+            self.preprocessor = ImagePreprocessor(conf)
 
     @torch.no_grad()
-    def __call__(self, image_path: Path,
-                 keypoints: np.ndarray = None,
-                 keypoint_ids: np.array = None,
-                 as_dict: Optional[bool] = True,
-                 overwrite_sparse: Optional[bool] = None):
+    def __call__(
+        self,
+        image_path: Path,
+        keypoints: np.ndarray = None,
+        keypoint_ids: np.array = None,
+        as_dict: Optional[bool] = True,
+        overwrite_sparse: Optional[bool] = None,
+    ):
         """
         Extract set of featuremaps for an image at image_path.
 
@@ -113,16 +146,30 @@ class FeatureExtractor:
 
         self.check_req_memory(image_path, keypoints)
         pyr_scales = self.conf["pyr_scales"]
-        img_orig = PIL.Image.open(image_path)  # does actually not load data
-        img_size = img_orig.size
-        if self.conf.fast_image_load:
-            # if the initial image size is very large and we need to do
-            # expensive downsampling, this can significantly speed up loading
-            # by just getting a smaller, sufficiently big slice of the image
-            # but at a slightly reduced quality
-            img_orig.draft(
-                'RGB', self.get_scaled_image_size(img_orig, pyr_scales[0])
-            )
+        if self.dataset is None:
+            # original behaviour
+            img_orig = PIL.Image.open(image_path)  # does actually not load data
+            img_size = img_orig.size
+            if self.conf.fast_image_load:
+                # if the initial image size is very large and we need to do
+                # expensive downsampling, this can significantly speed up loading
+                # by just getting a smaller, sufficiently big slice of the image
+                # but at a slightly reduced quality
+                img_orig.draft("RGB", self.get_scaled_image_size(img_orig, pyr_scales[0]))
+        elif self.dataset == "megadepth" or self.dataset == "scannet1500":
+            tensor_img = load_image(image_path, False)
+            tensor_img = self.preprocessor(tensor_img)["image"]
+            # img_orig = PIL.Image.fromarray(cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB))
+            img_orig = tensor_to_pil(tensor_img)
+            img_size = img_orig.size
+        elif self.dataset == "KITTI":
+            resize_image_to_width = 1240
+            resize_image_to_height = 376
+            image_cv = load_and_resize_img_kitti(image_path, resize_image_to_width, resize_image_to_height)
+            img_orig = PIL.Image.fromarray(image_cv)
+            img_size = img_orig.size
+        else:
+            raise ValueError(f"Unknown dataset {self.dataset}.")
         fmaps = []
         for pyr_scale in pyr_scales:
             img_pyr = self.resize_image(img_orig, pyr_scale)
@@ -130,33 +177,34 @@ class FeatureExtractor:
             feats = self.model(img_tens)
 
             for i, channels in enumerate(self.model.output_dims):
-                assert(channels == int(feats[i].shape[1]))
+                assert channels == int(feats[i].shape[1])
 
-                fmaps.append(self.tensor_to_fmap(
-                                feats[i], img_size,
-                                keypoints, keypoint_ids, as_dict=as_dict,
-                                overwrite_sparse=overwrite_sparse))
+                fmaps.append(
+                    self.tensor_to_fmap(
+                        feats[i], img_size, keypoints, keypoint_ids, as_dict=as_dict, overwrite_sparse=overwrite_sparse
+                    )
+                )
             torch.cuda.empty_cache()
         return fmaps
 
-    def get_scaled_image_size(self, image: PIL.Image,
-                              pyr_scale: Optional[float] = 1.0):
+    def get_scaled_image_size(self, image: PIL.Image, pyr_scale: Optional[float] = 1.0):
         w, h = image.size
-        return [int(round(min(self.conf["max_edge"] / max(w, h), 1)
-                * x * pyr_scale)) for x in [w, h]]
+        return [int(round(min(self.conf["max_edge"] / max(w, h), 1) * x * pyr_scale)) for x in [w, h]]
 
     def resize_image(self, image: PIL.Image, pyr_scale: float):
         w_new, h_new = self.get_scaled_image_size(image, pyr_scale)
         return image.resize((w_new, h_new), self.filters[self.conf.resize])
 
-    def tensor_to_fmap(self, featuremap: torch.Tensor,
-                       image_size: Tuple[int, int],
-                       keypoints: np.ndarray = None,
-                       keypoint_ids: np.array = None,
-                       as_dict: Optional[bool] = True,
-                       overwrite_sparse: Optional[bool] = None):
-        sparse =\
-            self.conf.sparse if overwrite_sparse is None else overwrite_sparse
+    def tensor_to_fmap(
+        self,
+        featuremap: torch.Tensor,
+        image_size: Tuple[int, int],
+        keypoints: np.ndarray = None,
+        keypoint_ids: np.array = None,
+        as_dict: Optional[bool] = True,
+        overwrite_sparse: Optional[bool] = None,
+    ):
+        sparse = self.conf.sparse if overwrite_sparse is None else overwrite_sparse
         w, h = image_size
         ps = self.conf["patch_size"]
 
@@ -164,13 +212,10 @@ class FeatureExtractor:
             if keypoint_ids is None:
                 keypoint_ids = list(range(keypoints.shape[0]))
             elif keypoints.shape[0] != len(keypoint_ids):
-                raise ValueError(
-                    "Number of provided keypoint_ids and keypoints "
-                    "do not match.")
+                raise ValueError("Number of provided keypoint_ids and keypoints " "do not match.")
 
         if sparse and keypoints is None:
-            raise RuntimeError("Cannot run sparse feature extraction " +
-                               "without any keypoints.")
+            raise RuntimeError("Cannot run sparse feature extraction " + "without any keypoints.")
 
         if self.conf.l2_normalize:
             featuremap = torch.nn.functional.normalize(featuremap, dim=1)
@@ -181,8 +226,7 @@ class FeatureExtractor:
         _, c, h, w = featuremap.shape
         # check whether sparse or dense requires less memory
         if keypoints is not None:
-            better_sparse = torch.numel(featuremap) > (keypoints.shape[0] *
-                                                       ps * ps * c)
+            better_sparse = torch.numel(featuremap) > (keypoints.shape[0] * ps * ps * c)
         else:
             # without keypoints sparse is anyway not possible
             better_sparse = False
@@ -191,24 +235,19 @@ class FeatureExtractor:
             # store as real sparse patches
             corners = (keypoints * scale - ps / 2.0).astype(np.int32)
             corners = np.clip(corners, [0, 0], np.array([w, h]) - ps - 1)
-            patches = extract_patches_numpy(featuremap.squeeze(0),
-                                            corners, ps)
-            metadata = {"scale": scale, "is_sparse": True,
-                        "patch_size": ps}
-            data = {"patches": patches,
-                    "corners": corners,
-                    "keypoint_ids": keypoint_ids,
-                    "metadata": metadata}
+            patches = extract_patches_numpy(featuremap.squeeze(0), corners, ps)
+            metadata = {"scale": scale, "is_sparse": True, "patch_size": ps}
+            data = {"patches": patches, "corners": corners, "keypoint_ids": keypoint_ids, "metadata": metadata}
         elif not sparse or not self.conf.use_cache or not as_dict:
             # Store as real dense patch --> also loads dense!
             corners = np.array([[0.0, 0.0]])
-            metadata = {"scale": scale, "is_sparse": False,
-                        "patch_size": ps}
-            data = {"patches": np.ascontiguousarray(
-                        featuremap.permute(0, 2, 3, 1).cpu().numpy()),
-                    "corners": corners,
-                    "keypoint_ids": [features.kDenseId],
-                    "metadata": metadata}
+            metadata = {"scale": scale, "is_sparse": False, "patch_size": ps}
+            data = {
+                "patches": np.ascontiguousarray(featuremap.permute(0, 2, 3, 1).cpu().numpy()),
+                "corners": corners,
+                "keypoint_ids": [features.kDenseId],
+                "metadata": metadata,
+            }
         else:
             # dense data, but load sparse from cache in featuremap.cc
             # significantly reduces disk storage on semi-dense matches
@@ -217,38 +256,29 @@ class FeatureExtractor:
             # to store this format to H5.
             corners = (keypoints * scale - ps / 2.0).astype(np.int32)
             corners = np.clip(corners, [0, 0], np.array([w, h]) - ps - 1)
-            metadata = {"scale": scale, "is_sparse": False,
-                        "patch_size": ps}
-            data = {"patches": np.ascontiguousarray(
-                        featuremap.permute(0, 2, 3, 1).cpu().numpy()),
-                    "corners": corners,
-                    "keypoint_ids": keypoint_ids,
-                    "metadata": metadata}
+            metadata = {"scale": scale, "is_sparse": False, "patch_size": ps}
+            data = {
+                "patches": np.ascontiguousarray(featuremap.permute(0, 2, 3, 1).cpu().numpy()),
+                "corners": corners,
+                "keypoint_ids": keypoint_ids,
+                "metadata": metadata,
+            }
 
         if as_dict:
             return data
         else:
-            return features.FeatureMap(
-                data["patches"],
-                data["keypoint_ids"],
-                data["corners"],
-                data["metadata"]
-            )
+            return features.FeatureMap(data["patches"], data["keypoint_ids"], data["corners"], data["metadata"])
 
     def check_req_memory(self, image_path: Path, keypoints: np.ndarray = None):
         num_kps = 0 if keypoints is None else keypoints.shape[1]
         return check_memory(self.estimate_req_memory(image_path, num_kps))
 
-    def estimate_req_memory(self, image_path: Path,
-                            num_kps: int):
+    def estimate_req_memory(self, image_path: Path, num_kps: int):
         n_bytes = self.dtype_to_bytes[self.conf.dtype]
         req_memory = 0
 
         if self.conf.sparse:
-            req_memory += (
-                self.conf.patch_size**2
-                * sum(self.channels_per_level) * num_kps * n_bytes
-            )
+            req_memory += self.conf.patch_size**2 * sum(self.channels_per_level) * num_kps * n_bytes
         else:
             if self.model.scales is None:
                 return np.nan
@@ -257,8 +287,5 @@ class FeatureExtractor:
             for pyr_scale in self.conf.pyr_scales:
                 w, h = self.get_scaled_image_size(image, pyr_scale)
                 for i, c in enumerate(self.model.output_dims):
-                    req_memory += (
-                        w * h * pyr_scale**2
-                        * self.model.scales[i]**2 * c * n_bytes
-                    )
+                    req_memory += w * h * pyr_scale**2 * self.model.scales[i] ** 2 * c * n_bytes
         return req_memory
diff --git a/pixsfm/refine_colmap.py b/pixsfm/refine_colmap.py
index 4da2b15..4b97382 100644
--- a/pixsfm/refine_colmap.py
+++ b/pixsfm/refine_colmap.py
@@ -15,31 +15,31 @@ from .features import FeatureManager
 from .features.extractor import FeatureExtractor
 from .bundle_adjustment import BundleAdjuster
 from .keypoint_adjustment import KeypointAdjuster, build_matching_graph
-from .util.colmap import (
-    read_keypoints_from_db, read_matches_from_db, write_keypoints_to_db
-)
+from .util.colmap import read_keypoints_from_db, read_matches_from_db, write_keypoints_to_db
 
 
 class PixSfM:
-    default_conf = OmegaConf.create({
-        "dense_features": {
-            **FeatureExtractor.default_conf
-        },
-        "interpolation": interpolation_default_conf,
-        "KA": {
-            **KeypointAdjuster.default_conf,
-            "interpolation": "${..interpolation}",
-        },
-        "BA": {
-            **BundleAdjuster.default_conf,
-            "interpolation": "${..interpolation}",
-        },
-    })
+    default_conf = OmegaConf.create(
+        {
+            "dense_features": {**FeatureExtractor.default_conf},
+            "interpolation": interpolation_default_conf,
+            "KA": {
+                **KeypointAdjuster.default_conf,
+                "interpolation": "${..interpolation}",
+            },
+            "BA": {
+                **BundleAdjuster.default_conf,
+                "interpolation": "${..interpolation}",
+            },
+        }
+    )
 
     def __init__(
-            self,
-            conf: Optional[Union[str, Dict, DictConfig]] = None,
-            extractor: Optional[FeatureExtractor] = None):
+        self,
+        conf: Optional[Union[str, Dict, DictConfig]] = None,
+        extractor: Optional[FeatureExtractor] = None,
+        dataset: Optional[str] = None,
+    ):
         self.conf = deepcopy(self.default_conf)
         if conf is not None:
             if isinstance(conf, str):
@@ -52,86 +52,93 @@ class PixSfM:
 
         self.extractor = extractor
         if self.extractor is None:
-            self.extractor = FeatureExtractor(self.conf.dense_features)
+            self.extractor = FeatureExtractor(self.conf.dense_features, dataset=dataset)
         self.keypoint_adjuster = KeypointAdjuster.create(self.conf.KA)
         self.bundle_adjuster = BundleAdjuster.create(self.conf.BA)
 
     def run_ka(
-            self,
-            keypoints: Dict[str, np.ndarray],
-            image_dir: Path,
-            pairs: List[Tuple[str]],
-            matches_scores: Tuple[List[np.ndarray]],
-            cache_path: Optional[Path] = None,
-            feature_manager: Optional[FeatureManager] = None):
+        self,
+        keypoints: Dict[str, np.ndarray],
+        image_dir: Path,
+        pairs: List[Tuple[str]],
+        matches_scores: Tuple[List[np.ndarray]],
+        cache_path: Optional[Path] = None,
+        feature_manager: Optional[FeatureManager] = None,
+    ):
+        import time
+
+        # t_0 = time.time()
         cache_path = self.resolve_cache_path(cache_path)
         graph = build_matching_graph(pairs, *matches_scores)
+        # t_1 = time.time()
+        # print(f"Graph building time: {t_1 - t_0:.4f} s")
+        # t_0 = time.time()
         if feature_manager is None:
             feature_manager = extract.features_from_graph(
-                self.extractor,
-                image_dir,
-                graph,
-                keypoints_dict=keypoints,
-                cache_path=cache_path
+                self.extractor, image_dir, graph, keypoints_dict=keypoints, cache_path=cache_path
             )
-        ka_data = self.keypoint_adjuster.refine_multilevel(
-                keypoints, feature_manager, graph)
+        # t_1 = time.time()
+        # print(f"Feature extraction time: {t_1 - t_0:.4f} s")
+        t_0 = time.time()
+        ka_data = self.keypoint_adjuster.refine_multilevel(keypoints, feature_manager, graph)
+        t_1 = time.time()
+        # print(f"Keypoint adjustment time: {t_1 - t_0:.4f} s")
+        pixsfm_internal_refinement_time_wo_s2dnet = t_1 - t_0
         del graph
-        return keypoints, ka_data, feature_manager
+        return keypoints, ka_data, feature_manager, pixsfm_internal_refinement_time_wo_s2dnet
 
     def run_ba(
-            self,
-            reconstruction: pycolmap.Reconstruction,
-            image_dir: Path,
-            cache_path: Optional[Path] = None,
-            feature_manager: Optional[FeatureManager] = None):
+        self,
+        reconstruction: pycolmap.Reconstruction,
+        image_dir: Path,
+        cache_path: Optional[Path] = None,
+        feature_manager: Optional[FeatureManager] = None,
+    ):
         cache_path = self.resolve_cache_path(cache_path)
         if feature_manager is None:
             feature_manager = extract.features_from_reconstruction(
-                    self.extractor, reconstruction, image_dir,
-                    cache_path=cache_path)
-        ba_data = self.bundle_adjuster.refine_multilevel(
-                reconstruction, feature_manager)
+                self.extractor, reconstruction, image_dir, cache_path=cache_path
+            )
+        ba_data = self.bundle_adjuster.refine_multilevel(reconstruction, feature_manager)
         return reconstruction, ba_data, feature_manager
 
     def refine_keypoints_from_db(
-            self,
-            output_path: Path,
-            database_path: Path,
-            image_dir: Path,
-            cache_path: Optional[Path] = None,
-            feature_manager: Optional[FeatureManager] = None):
+        self,
+        output_path: Path,
+        database_path: Path,
+        image_dir: Path,
+        cache_path: Optional[Path] = None,
+        feature_manager: Optional[FeatureManager] = None,
+    ):
         cache_path = self.resolve_cache_path(cache_path, output_path.parent)
         keypoints = read_keypoints_from_db(database_path)
         pairs, matches, scores = read_matches_from_db(database_path)
         keypoints, ka_data, feature_manager = self.run_ka(
-                keypoints, image_dir, pairs, (matches, scores), cache_path,
-                feature_manager)
+            keypoints, image_dir, pairs, (matches, scores), cache_path, feature_manager
+        )
         if database_path != output_path:
             shutil.copy(database_path, output_path)
         write_keypoints_to_db(output_path, keypoints)
         return keypoints, ka_data, feature_manager
 
     def refine_reconstruction(
-            self,
-            output_path: Path,
-            input_path: Path,
-            image_dir: Path,
-            cache_path: Optional[Path] = None,
-            feature_manager: Optional[FeatureManager] = None):
+        self,
+        output_path: Path,
+        input_path: Path,
+        image_dir: Path,
+        cache_path: Optional[Path] = None,
+        feature_manager: Optional[FeatureManager] = None,
+    ):
         reconstruction = pycolmap.Reconstruction(str(input_path))
         cache_path = self.resolve_cache_path(cache_path, output_path)
         reconstruction, ba_data, feature_manager = self.run_ba(
-                reconstruction, image_dir, cache_path=cache_path,
-                feature_manager=feature_manager)
+            reconstruction, image_dir, cache_path=cache_path, feature_manager=feature_manager
+        )
         output_path.mkdir(exist_ok=True, parents=True)
         reconstruction.write(str(output_path))
         return reconstruction, ba_data, feature_manager
 
-    def resolve_cache_path(
-            self,
-            cache_path: Optional[Path] = None,
-            output_dir: Optional[Path] = None):
+    def resolve_cache_path(self, cache_path: Optional[Path] = None, output_dir: Optional[Path] = None):
         feature_conf = self.extractor.conf
         feature_name = feature_conf.model.name
         if cache_path is None:
@@ -141,56 +148,47 @@ class PixSfM:
                 return None
         if cache_path.suffix != ".h5":
             cache_path = cache_path / "{}_featuremaps_{}.h5".format(
-                feature_name, "sparse" if feature_conf.sparse else "dense")
+                feature_name, "sparse" if feature_conf.sparse else "dense"
+            )
         return cache_path
 
 
 def add_common_args(parser):
     parser.add_argument(
-        '--config', type=parse_config_path,
-        help="Path to the YAML configuration file "
-        f"or the name of a default config among {list(default_configs)}.")
-    parser.add_argument(
-        '--image_dir', type=Path, required=True,
-        help='Path to the directory containing the images.')
-    parser.add_argument(
-        '--cache_path', type=Path,
-        help="Path to the HDF5 cache file for dense features.")
-    parser.add_argument(
-        'dotlist', nargs='*', help="Additional configuration modifiers.")
+        "--config",
+        type=parse_config_path,
+        help="Path to the YAML configuration file " f"or the name of a default config among {list(default_configs)}.",
+    )
+    parser.add_argument("--image_dir", type=Path, required=True, help="Path to the directory containing the images.")
+    parser.add_argument("--cache_path", type=Path, help="Path to the HDF5 cache file for dense features.")
+    parser.add_argument("dotlist", nargs="*", help="Additional configuration modifiers.")
 
 
 def add_ka_args(subparsers):
-    parser_ka = subparsers.add_parser(
-        'keypoint_adjuster', aliases=['ka'], help='Refine keypoints.')
+    parser_ka = subparsers.add_parser("keypoint_adjuster", aliases=["ka"], help="Refine keypoints.")
+    parser_ka.add_argument("--database_path", type=Path, required=True, help="Input COLMAP database.")
     parser_ka.add_argument(
-        '--database_path', type=Path, required=True,
-        help='Input COLMAP database.')
-    parser_ka.add_argument(
-        '--output_path', type=Path,
-        help='Output database. If not provided, the refinement is in-place.')
+        "--output_path", type=Path, help="Output database. If not provided, the refinement is in-place."
+    )
     add_common_args(parser_ka)
     return parser_ka
 
 
 def add_ba_args(subparsers):
     parser_ba = subparsers.add_parser(
-        'bundle_adjuster', aliases=['ba'],
-        help='Refine camera poses and 3D points in an SfM model.')
-    parser_ba.add_argument(
-        '--input_path', type=Path, required=True,
-        help='Input SfM model in text or binary format.')
+        "bundle_adjuster", aliases=["ba"], help="Refine camera poses and 3D points in an SfM model."
+    )
+    parser_ba.add_argument("--input_path", type=Path, required=True, help="Input SfM model in text or binary format.")
     parser_ba.add_argument(
-        '--output_path', type=Path,
-        help='Output SfM model. If not provided, the refinement is in-place.')
+        "--output_path", type=Path, help="Output SfM model. If not provided, the refinement is in-place."
+    )
     add_common_args(parser_ba)
     return parser_ba
 
 
 if __name__ == "__main__":
     parser = argparse.ArgumentParser()
-    subparsers = parser.add_subparsers(
-        title='Available commands', dest='command', required=True)
+    subparsers = parser.add_subparsers(title="Available commands", dest="command", required=True)
     add_ka_args(subparsers)
     add_ba_args(subparsers)
 
@@ -200,13 +198,13 @@ if __name__ == "__main__":
         conf = OmegaConf.merge(OmegaConf.load(args.config), conf)
     sfm = PixSfM(conf)
 
-    if args.command in ('keypoint_adjuster', 'ka'):
+    if args.command in ("keypoint_adjuster", "ka"):
         logger.info("Will refine keypoints from a COLMAP database.")
         sfm.refine_keypoints_from_db(
-            args.output_path or args.database_path,
-            args.database_path, args.image_dir, cache_path=args.cache_path)
-    elif args.command in ('bundle_adjuster', 'ba'):
+            args.output_path or args.database_path, args.database_path, args.image_dir, cache_path=args.cache_path
+        )
+    elif args.command in ("bundle_adjuster", "ba"):
         logger.info("Will refine an existing COLMAP model.")
         sfm.refine_reconstruction(
-            args.output_path or args.input_path,
-            args.input_path, args.image_dir, cache_path=args.cache_path)
+            args.output_path or args.input_path, args.input_path, args.image_dir, cache_path=args.cache_path
+        )
diff --git a/third-party/HighFive b/third-party/HighFive
--- a/third-party/HighFive
+++ b/third-party/HighFive
@@ -1 +1 @@
-Subproject commit b2f49c04cc3ddc45a05db9d4e5f45cd34778cb8e
+Subproject commit b2f49c04cc3ddc45a05db9d4e5f45cd34778cb8e-dirty
diff --git a/third-party/pybind11 b/third-party/pybind11
--- a/third-party/pybind11
+++ b/third-party/pybind11
@@ -1 +1 @@
-Subproject commit f7b499615e14d70ab098a20deb0cdb3889998a1a
+Subproject commit f7b499615e14d70ab098a20deb0cdb3889998a1a-dirty
